{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "<img src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/solutions-microsoft-logo-small.png?raw=true\" alt=\"Microsoft\">\r\n<br>\r\n\r\n# Workshop: Microsoft SQL Server Machine Learning Services\r\n\r\n#### <i>A Microsoft Course from the SQL Server team</i>\r\n\r\n## 03 - Phase 1: Business Understanding\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/textbubble.png?raw=true\"><b>Business Understanding</b></p>\r\n\r\n<br>\r\n<br>\r\n<br>\r\n\r\nYou're learning to use the Team Data Science Process to create a complete solution, using SQL Server as the platform. The phases in the Team Data Science process are:\r\n\r\n<dl>\r\n  <dt>1 - Business Understanding <i>(This module)</i></dt>\r\n  <dt>2 - Data Acquisition and Understanding</dt>\r\n  <dt>3 - Modeling</dt>\r\n  <dt>4 - Deployment</dt>\r\n  <dt>5 - Customer Acceptance and Model Retraining</dt>\r\n<dl>\r\n\r\nNow that the Project is underway (the *Implementation* in your project plan), you'll follow the Data Science Process for teams, and implement each step in an actual implementation. You'll begin with a deeper discovery session for determining the best model type and hyperparameters you need for the prediction.\r\n\r\nDuring the *Discovery*, *Envisioning* and *ADS* steps the customer explained the type of answer they were looking for. In this case, the answer involves grouping customers together (a *Cluster*), and that means you need to create and train a Machine Learning Model that will use current data for training, so that it can make predictions over data it has not seen. The Project steps are less specific than the phases you need for a Data Science project, since it's important to get the data (features and labels) the process needs. That's what the Business Understanding phase does.\r\n\r\nIn the *Business Understanding* phase of the Team Data Science Process the Data Science team determines the prediction or categorical work your organization wants to create. You'll also review the project planning documents, locate your initial data source locations, and set up the environment you will use to create and operationalize your models. This phase involves a great deal of coordination among the team and the broader organization.\r\n\r\n<p style=\"border-bottom: 1px solid lightgrey;\"></p>\r\n\r\n### Goals for Business Understanding\r\n\r\n- Specify the key variables that are to serve as the model targets and whose related metrics are used determine the success of the project.\r\n- Identify the relevant data sources that the business has access to or needs to obtain.\r\n \r\n<p style=\"border-bottom: 1px solid lightgrey;\"></p>\r\n\r\n### How to do it (There are two main tasks addressed in this stage)\r\n\r\n- Define objectives: Work with your customer and other stakeholders to understand and identify the business problems. Formulate questions that define the business goals that the data science techniques can target.\r\n- Identify data sources: Find the relevant data that helps you answer the questions that define the objectives of the project.\r\n\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/pin.jpg?raw=true\"><b>2.1 Setting up the Data Science Project</b></p>\r\n\r\nBegin by assembling your team. It should include at least a Data Scientist, a Data Engineer (data professional with Data Science team experience), a business or organizational representative, and the owner of the project. If the project is going to go forward, set up a schedule for the work that follows.\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/pin.jpg?raw=true\"><b>2.2 Find the Question</b></p>\r\n\r\nRemember that not every question can be answered by Machine Learning. Some questions can be solved with simple Linear Regression, Business Intelligence, or even a query in a report. Check the last module for the types of scenarios where Machine Learning works well.\r\n\r\nIn this case, the Wide World Importers' company leadership has the following goals:\r\n\r\n<i>Wide World Importers (WWI) is a wholesale novelty goods importer and distributor. As a wholesaler, WWI's customers are mostly companies who resell to individuals, but they do sell to individuals as well. \r\nWWI buys goods from suppliers including novelty and toy manufacturers, and other novelty wholesalers. They stock the goods in their WWI warehouse and reorder from suppliers as needed to fulfill customer orders. They also sell smaller specialty quantities as a convenience for customers.\r\nFor these higher value but higher expense clients, returns are becoming an issue. The leadership team has asked marketing, sales and finance to work together to figure out why the returns are increasing. As a first step, the three organizations have gathered data into an analysis database on the returns. They want to start by finding out what common features the customers that are returning items share.</i>",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/checkbox.png?raw=true\"><b>Activity: Defining the Business Problem</b></p>\r\n\r\n- Open the `./assets/Project` folder and review the project documents you see there.\r\n- What question does the company want answered? Which document does that go into? Open that document and ensure it's accurate.\r\n- Is this a prediction, a classification, or a clustering exercise? Or just reporting? Who can answer that question? Which document does that go into? Open that document and ensure it's accurate.\r\n- Based on that answer, will this be an end-result, or act as an input to other projects?\r\n- What are the specific requirements and constraints? Which document does that go into? Open that document and ensure it's accurate.\r\n- How will you know that the project is successful?\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/pin.jpg?raw=true\"><b>2.3 Document the Data Sources</b></p>\r\n\r\n\r\n\r\nGetting an accurate prediction involves having solid training data that is as predictive as possible. In most cases, this involves a preliminary investigation by the Data Scientist to determine the Features and Labels that would best fit a prediction or classification. This data may be on hand already, or you may need to acquire it. In some cases, the data does not exist that would create a good model, and in that case a set of proxy data may be used, or the collection of that data started and the project delayed until a representative dataset is available.\r\n\r\nIn the case of this course, the data is wholly contained within the Analysis database, and a generated data set for training we will use. However, you might think about other data sources that could be useful.\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/checkbox.png?raw=true\"><b>Activity: Restore the Database</b></p>\r\n\r\n- The dataset used in this course is hosted in a few SQL Server tables. The tables contain data from various systems on-premises over a period of time. You should have already downloaded this file during the pre-requisites phase, but if not, do so now - <a href=\"https://cs7a9736a9346a1x44c6xb00.blob.core.windows.net/backups/Analysis.bak\" target=\"_blank\">The backup (.bak) file is located here - note that it may take some time to download, so if you are in-class, the instructor may give you another location to speed the download</a> \r\n- Copy that file to this location on your Instance: `C:\\Program Files\\Microsoft SQL Server\\MSSQL15.MSSQLSERVER\\MSSQL\\Backup`. **TIP:** *You can use the `View | Command Pallet` And then type `terminal` to start a terminal in Azure Data Studio to type commands in command-line.*  \r\n- Restore the database using the following code - Note: You may have to change drive or paths depending on your system:\r\n",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "/* Restore Database */\nUSE [master]\n\nRESTORE DATABASE [Analysis] \nFROM  DISK = N'C:\\Program Files\\Microsoft SQL Server\\MSSQL15.MSSQLSERVER\\MSSQL\\Backup\\Analysis.bak' \nWITH  REPLACE\n, FILE = 1\n,  MOVE N'tpcxbb_1gb' TO N'C:\\Program Files\\Microsoft SQL Server\\MSSQL15.MSSQLSERVER\\MSSQL\\DATA\\tpcxbb_1gb.mdf'\n,  MOVE N'tpcxbb_1gb_log' TO N'C:\\Program Files\\Microsoft SQL Server\\MSSQL15.MSSQLSERVER\\MSSQL\\DATA\\tpcxbb_1gb.ldf'\n,  NOUNLOAD,  STATS = 5\nGO",
            "metadata": {},
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": "You should see the status of the restore operation. \r\n\r\n**NOTE**: *If you have an issue with the restore operation, check the file paths and names of the database objects. You can edit the script above until it matches your system. This backup was generated on a SQL Server 2019 Instance on Windows Server. If you are restoring to a later version or on Linux, you will need to add `WITH MOVE` or other qualifiers to the `RESTORE` command.*\r\n\r\nYou'll explore this database further in the next module.\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/pin.jpg?raw=true\"><b>2.4 Document the Data Sources</b></p>\r\n\r\nThere are many decisions you have to make for data sources, ingestion, and other path questions, so it's best to use a Decision Matrix tool. In this project's *ADS Decision Matrix* Excel spreadsheet, the choices inferred by the team are:\r\n\r\n- Use the data we have\r\n- Solicit further data\r\n- Synthesize the data by looking for similar use-cases\r\n\r\nIn the next Module, you will explore these options further.\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/checkbox.png?raw=true\"><b>Activity: Review Project Documents, Determine specific Questions, Document the Data Source</b></p>\r\n\r\n- Open the `./assets/Project` folder and review the documents you see there.\r\n- Open the **Decision Matrix** Excel Spreadsheet you see there and look through the choices. How do the requirements and constraints impact the technical decisions? *For now, assume these are the correct choices*.\r\n- Examine/Fill out (as time permits) the project Charter Document\r\n- Examine/Identify (as time permits) Data Sources\r\n- Examine/Create (as time permits) a Data Dictionary. Is there a way to create a Data Dictionary quickly using only T-SQL statements? Are there reports you could use?\r\n- Are there specific data elements that would be predictive or at least corollary for the groupings of customers in the data sample?\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/thinking.jpg?raw=true\"><b>For Further Study</b></p>\r\n\r\n<br>\r\n<br>\r\n\r\n- Business Understanding Reference:  https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle-business-understanding\r\n- See https://www.georgetownlawtechreview.org/re-identification-of-anonymized-data/GLTR-04-2017/ for a discussion on statistical obfuscation dangers and methods\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/education1.png?raw=true\"><b>Next</b>: Phase 2 - Data Acquisition and Understanding</p>\r\n\r\nNext, you'll continue following the Team Data Science Process with the next phase - *04 - Phase 2 - Data Acquisition and Understanding*. Open that Notebook to continue.\r\n",
            "metadata": {}
        }
    ]
}